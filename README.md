MU-PP Mark
Enhancing Traceability in Multi-User Diffusion Models via Prompt Perturbation Watermarking

ğŸ“„ Official PyTorch implementation of the paper:
â€œEnhancing Traceability in Multi-User Diffusion Models via Prompt Perturbation Watermarkingâ€

ğŸ” Overview
MU-PP Mark is an implicit multi-user watermarking framework designed for text-to-image diffusion models (e.g., Stable Diffusion).
It enables reliable user attribution and provenance tracing of generated images without modifying model architectures or parameters.

Key idea
Instead of embedding watermarks into pixels or model weights, MU-PP Mark:

Injects user-specific watermark tensors into the prompt embedding space
Propagates identity information throughout the diffusion process
Recovers ownership using contrastive learningâ€“based imageâ€“watermark matching
Fetched content

âœ¨ Features
âœ… Multi-user attribution (scales to dozens or hundreds of users)
âœ… No modification to diffusion model weights
âœ… Prompt-perturbation based implicit watermarking
âœ… High robustness to compression, noise, blur, and color attacks
âœ… High image fidelity (PSNR 37.01 dB @ Î± = 0.2)
âœ… 99% Top-1 identification accuracy
ğŸ“ Repository Structure
stable-diffusion/
â”œâ”€â”€ 1.watermark-injection/
â”‚   â”œâ”€â”€ single-marking.py        # Generate a single watermarked image
â”‚   â”œâ”€â”€ dataset-marking.py       # Generate large-scale watermarked dataset
â”‚   â”œâ”€â”€ watermark_tensor.py      # Watermark tensor generation
â”‚   â””â”€â”€ watermarks.pt            # Pre-generated watermark tensors
â”‚
â”œâ”€â”€ 2.train/
â”‚   â”œâ”€â”€ train.py                 # Contrastive training script
â”‚   â”œâ”€â”€ dataset.py               # Dataset loader
â”‚   â”œâ”€â”€ img_encoder.py           # Image encoder (ResNet-based)
â”‚   â”œâ”€â”€ watermark_encoder.py     # Watermark encoder ([77, 768] tensor)
â”‚   â””â”€â”€ clip.py                  # CLIP-based text encoder wrapper
â”‚
â””â”€â”€ 3.watermark_retrieval.py     # Watermark detection / user attribution
Each folder corresponds to a stage in the MU-PP Mark pipeline:

Watermark embedding
Multi-user contrastive training
Watermark detection
âš™ï¸ Installation
Requirements
Python â‰¥ 3.10
PyTorch â‰¥ 2.0
CUDA-enabled GPU recommended
Install dependencies:

pip install -r requirements.txt
Example requirements.txt:

torch>=2.0
torchvision
diffusers
transformers
numpy
opencv-python
lpips
tqdm
ğŸš€ Usage
1ï¸âƒ£ Watermark Embedding
Generate a single watermarked image
python 1.watermark-injection/single-marking.py \
  --prompt "A photo of a mountain landscape" \
  --user_id 0 \
  --alpha 0.2
Generate a watermarked dataset
python 1.watermark-injection/dataset-marking.py \
  --num_users 10 \
  --num_prompts 1000 \
  --alpha 0.2
Î± (watermark strength) controls the trade-off between image quality and watermark detectability.
Based on our experiments, Î± = 0.2 provides the best balance.

2ï¸âƒ£ Contrastive Training
Train the multi-user watermark retrieval model:

python 2.train/train.py \
  --batch_size 10 \
  --num_users 10 \
  --lr 1e-3 \
  --epochs 100
âš ï¸ Important:
The training batch size must equal the number of users, as each batch contains exactly one watermark per user.

3ï¸âƒ£ Watermark Detection (User Attribution)
Identify the source user of a generated image:

python 3.watermark_retrieval.py \
  --image_path example.png
The script outputs the user ID with the highest cosine similarity.

ğŸ“Š Experimental Results
Metric	Value
Top-1 Accuracy	0.99
PSNR	37.01 dB
SSIM	0.93
LPIPS	0.04
Strong intra-class compactness (â‰ˆ 0.25)
Clear inter-class separation (â‰ˆ 0.70)
Robust against JPEG compression, blur, noise, and color distortions
ğŸ” Reproducibility Notes
Watermark tensors are provided in watermarks.pt
Random seeds can be fixed in watermark_tensor.py
All experiments were conducted with Stable Diffusion + CLIP text encoder
ğŸ“œ License
This project is released under the MIT License.
See LICENSE for details.

ğŸ“– Citation
If you find this work useful, please cite:

@article{shi2025muppmark,
  title={Enhancing Traceability in Multi-User Diffusion Models via Prompt Perturbation Watermarking},
  author={Shi, Hui and Wang, Yuchen and Jin, Conghui and Liu, Mingyang},
  journal={},
  year={2025}
}
ğŸ™ Acknowledgements
This work was supported by:

Liaoning Provincial Science and Technology Joint Plan (No. 2025-MSLH-435)
National Natural Science Foundation of China (Grant No. 61601214)
